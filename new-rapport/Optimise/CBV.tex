\documentclass[../Optimise]{subfiles}
\begin{document}

\numberwithin{equation}{section}

\subsection{Call-by-value-semantik}
\label{sec:Optimise:CBV}
Våran första försök till en semantik var inte helt lyckad, den kunnde komma in i
oändliga loopar och var för aggresiv i sin optimering. Vi kommer här visa vad den
gjorde för att optimera de olika uttrycken som finns. För att visa vilket tillstånd
optimeringen är i har vi valt att skriva symbolen innan ett par hakparanteser för
att göra det mer lättläst. Så en konfiguration som är i $\Omega$ tillståndet skrivs:

\[
\OMEGA sHe
\]


\paragraph{Funktionsapplikationer}
Om alla argument till en känd funktion är kända kan vi direkt evaluera detta funktionsanrop,
vilket visas i regel \eqref{CBV:Fun1}. I \eqref{CBV:Fun2} finns ett argument som
är känt och vi kommer att infoga hela funktionen. Den infogningen sker via en \cont{OIlining}-continuation
som kommer substituera in argumenten i funktionskroppen. Om ingen av dessa regler
matchades så kan vi inte optimera mer, regel \eqref{CBV:FunIrr} visar detta genom
att använda $\Phi$ tillståndet.

\begin{align}
\label{CBV:Fun1} \OMEGA sH{f\,\many{k}}  \Rightarrow &\, \mc{f\,\many{k}}sH\\
 & \many{k} \text{ alla kända} \nonumber \\
\label{CBV:Fun2} \OMEGA sH{f\,\many{x}\, k\,\many{y}}  \Rightarrow &\, \mc{f\,\many{x}\, k\,\many{y}}{\oInline s}H\\
 & \many{x},\many{y} \text{ okänd, } k \text{ är känd} \nonumber \\
\label{CBV:FunIrr} \OMEGA sH{f\,\many{x}} \Rightarrow &\, \IRR sH{f\,\many{x}}
\end{align}

Då vi inte lägger ut någon continuation för just applikationen finns det ingen regel
ifrån $\Psi$ samt $\Phi$ tillstånden.



\paragraph{Let-uttryck}

Om \kw{let}-uttryck binder ett thunk-objekt så har vi valt att först evaluera thunk-uttrycket
detta för att kunna optimera mera kod som beror på värdet av thunk-uttrycket. Ifall
man är i tillståndet $\Psi$ \eqref{CBV:LetTPsi} har vi lyckats evaluera thunken till ett värde och kan
substituera in det värdet i kroppen av \kw{let}. Medans i $\Phi$ \eqref{CBV:LetTIrr} kunnde vi inte
optimera till ett värde, så vi stoppar tillbaka värdet för thunken och fortsätter att
optimera kroppen. Notera positionen av $\bullet$ i den regeln ändras för att tala om
var vi optimerar.

\begin{align}
\label{CBV:LetTOmg} \OMEGA sH{\eLet x{\THUNK e}{e'}}  \Rightarrow &\, \OMEGA{\oLet x{e'}s}He\\
\label{CBV:LetTPsi} \PSI{\oLet xes}Hv  \Rightarrow &\, \OMEGA sH{e[v/x]} \\
\label{CBV:LetTIrr} \IRR{\oLet xes}H{e'}  \Rightarrow &\, \OMEGA{\oLetObj x{\THUNK{e'}}s}He
\end{align}

Om objektet inte var en thunk kan två olika saker ske, \eqref{CBV:OLet1} är ifall 
vi har en känd \kw{CON}. Då allokerar vi den på heapen på samma sätt som maskinen
och fortsätter att optimera det inre uttrycket. I regel \eqref{CBV:OLet2} så 
fortsätter vi bara optimera med det inre uttrycket. Här är alltså objekten
inte thunkar.

$\Psi$ och $\Phi$ bygger bara upp \kw{let}-uttrycket igen och går vidare med $\Phi$ tillståndet
då det betyder att vi har optimerat klart. Ett problem här är att om vi har en \kw{let}
i en \kw{case}-granskare så kommer ingen gren att väljas, trots att det finns ett värde.

\begin{codeEx}
foo x = case (let y = CON (X 2) in y) of
    { X z -> ..
    };
\end{codeEx} 

I detta fall vet vi att värdet på granskaren är konstruktorn \ic{X} och att \ic{z} är $2$, men vår optimering
kommer inte att se detta. Det här är ytterligare en brist som löses senare i detta arbete.

\begin{align}
\label{CBV:OLet1} \OMEGA sH{\eLet x{\CON{C}{\many{a}}}{e}}  \Rightarrow &\, \OMEGA{\oLetObj x{OBJ}s}{\heap{v}{\CON{C}{\many{a}}}}e\\
 & \many{a} \text{ alla kända, } v \text{ ny variabel} \nonumber \\
\label{CBV:OLet2}\OMEGA sH{\eLet x{OBJ}{e}}  \Rightarrow &\, \OMEGA{\oLetObj x{OBJ}s}He\\
\PSI{\oLetObj x{OBJ}s}Hv  \Rightarrow &\, \IRR sH{\eLet x{OBJ}v}\\
\IRR{\oLetObj x{OBJ}s}He  \Rightarrow &\, \IRR sH{\eLet x{OBJ}e}
\end{align}


\paragraph{Case}
\label{cbv:case}
För att kunna optimera ett \kw{case}-uttryk så behöver vi veta vad granskaren är
så i $\Omega$\eqref{CBV:CaseOmg} tillståndet börjar vi optimera granskaren, vi lägger ut en
\cont{OCase}-continuation för att komma ihåg att vi var i en \kw{case}.

I $\Psi$\eqref{CBV:CasePsi} tillståndet har att det är ett värde och vi  väljer 
helt enkelt vilken gren som matchar värdet som maskinen arbetat fram, och instansiera den.
Detta är troligtvis ett av de viktigaste stegen i vår optimering då det skalar bort alla onödiga 
grenar, minskar koden och oftast kan fortsätta optimera en bit in det nya uttrycket.

Istället för att skapa en $\eCase e brs$ i \eqref{CBV:CaseIrr} finns även
funktionalitet för att
optimera varje gren Detta bryter dock semantiken eftersom optimeringen kan fastna
i en oändlig loopar när den optimerar grenar som programmet aldrig hade exekverat
vid en vanlig körning: 

\begin{codeEx}
case x of
    { True  -> 5 : Nil
    ; False -> repeat 1
    }
\end{codeEx}

Om \ic{x} är okänt under optimeringen och den optimerar i grenarna kommer den
att infoga \ic{repeat 1} obegränsat. Detta är felaktigt då denna loop bara skulle uppstå
om \ic{x} någon gång var \kw{False}.

\begin{align}
\label{CBV:CaseOmg} \OMEGA sH{\eCase e{brs}} \Rightarrow &\, \OMEGA{\oCase{brs}s}He\\
\label{CBV:CasePsi} \PSI{\oCase{brs}s}Hv \Rightarrow &\, \OMEGA sH{\text{instansiera korrekt gren av brs med v}} \\
\label{CBV:CaseIrr} \IRR{\oCase{brs}s}He \Rightarrow &\, \IRR sH{\eCase e brs}
\end{align}


\paragraph{Atomer}
Om det finns en variabel som kod, och denna pekar på thunk i heapen, så börjar vi
optimera uttrycket den pekar på. Medans alla andra atomer är värden och vi kan gå
till $\Psi$ tillståndet.
\begin{align}
\OMEGA s{\heap{v}{\THUNK{e}}}v \Rightarrow &\, \OMEGA sHe \\
\OMEGA sHa \Rightarrow &\, \PSI sHa
\end{align}


\paragraph{Gränssnitt mot STG}
När vi interagerar med STG-maskinen måste vi ha tydliga regler
för när maskinen ska sluta evaluera och börja optimera. Detta sker
antingen då den stöter på en $\OPT t$ för första gången, eller när den
inte längre kan evaluera ett uttryck och har en Optimise continuation
på stacken.

\begin{align}
\mc as{\heap a{\OPT t}} & \Rightarrow\\
\mc t{\cOPT{a\,}s}{\heap a{\BH}} \nonumber
\end{align}
Den här regler sätter upp maskinen i läge för att optimera atomen $a$. Men om $a$
är en thunk behöver den först evalueras till ett värde. Därför läggs
OPT-continuationen ut för att skrida till verket då maskinen har evaluerat
$a$ till ett värde.

\begin{align}
\mc x{\cOPT as}{\heapp x{\PAP f{a_{1}\ldots a_{n}}}f{\FUN{x_{1}\ldots x_{m}}e}} & \Rightarrow\\
\OMEGA{\cOFUN{x_{n+1}\ldots x_{m}}as}H{e[a_{1}/x_{1}\ldots a_{n}/x_{n}]} \nonumber
\end{align}

Nu har vi ett PAP-värde och vi kan börja optimera funktionen. De kända 
argumenten substitueras in.

\begin{align}
\label{CBV:Fun3} \IRR{\cOFUN{\many{x}}{\alpha}s}He  \Rightarrow &\, \mc{\alpha}s{\heap{\alpha}{\FUN{\many{x}}e}}
\end{align}
 I regel \eqref{CBV:Fun3} kommer att vara för tillstånd
 $\Phi$ och vi skall återigen bygga upp (en förhopningsvis optimerad) funktion.

\begin{align}
\mc v{O.\star\,:\, s}{\nheap v{\THUNK e}} & \Rightarrow\\
\PSI{O.\star\,:\, s}Hv \nonumber
\end{align}
Ibland används maskinen för att evaluera t.ex. konstantuttryck under optimeringen.
Dessa reduceras alltid till ett värde och då anropas $\psi$ som tar hand 
om detta värde.

%\NOTE {
%\begin{align*}
%\OMEGA sH{\eCase e{brs}} & \Rightarrow & \OMEGA{\oCase{brs}s}He\\
%\OMEGA sH{f\,\bar{k}} & \Rightarrow & \mc{f\,\bar{k}}sH\\
%\OMEGA sH{f\,\bar{x}\, k\,\bar{y}} & \Rightarrow & \mc{f\,\bar{x}\, k\,\bar{y}}{\oInline s}H\\
%\OMEGA sH{\eLet x{\THUNK e}{e'}} & \Rightarrow & \OMEGA{\oLet x{e'}s}He\\
%\OMEGA s{\nheap x{\,}}{\bullet} & \Rightarrow & \IRR sH{\bullet}
%\end{align*}
%
%\begin{align*}
%\PSI{\oLet xes}Hv & \Rightarrow & \OMEGA sH{e[v/x]}
%\end{align*}
%
%\begin{align*}
%\PSI{\oLetObj x{OBJ}s}Hv & \Rightarrow & \IRR sH{\eLet x{OBJ}v}\\
%\PSI{\oCase{brs}s}Hv & \Rightarrow & \OMEGA sH{\text{instantiate correct brs with v}}\end{align*}
%
%\begin{align*}
%\IRR{\oLet xes}H{e'} & \Rightarrow & \OMEGA{\oLetObj x{\THUNK{e'}}s}He\\
%\IRR{\oCase{brs}s}He & \Rightarrow & \IRR sH{\eCase e brs}
%\end{align*}
%
%\begin{align*}
%\IRR{\oLetObj x{OBJ}s}He & \Rightarrow & \IRR sH{\eLet x{OBJ}e}\\
%\IRR{\cOFUN{\bar{x}}{\alpha}s}He & \Rightarrow & \mc{\alpha}s{\heap{\alpha}{\FUN{\bar{x}}e}}
%\end{align*}
%
%När vi interagerar med STG maskinen måste vi har tydliga regler
%för när maskien ska sluta evaluera och börja optimera. Detta sker
%antingen då den stöter på en $\OPT t$ för första gången, eller när den
%inte längre kan evaluera ett uttryck och har en Optimise continuation
%på stacken.

%\begin{align*}
%\mc as{\heap a{\OPT t}} & \Rightarrow\\
%\mc t{\cOPT{a\,}s}{\heap a{\BH}}\\
%\mc x{\cOPT as}{\heapp x{\PAP f{a_{1}\cdots a_{n}}}f{\FUN{x_{1}\cdots x_{m}}e}} & \Rightarrow\\
%\OMEGA{\cOFUN{x_{n+1}\cdots x_{m}}as}H{e[a_{1}/x_{1}\cdots a_{n}/x_{n}]}\\
%\mc v{O.\star\,:\, s}{\nheap v{\THUNK e}} & \Rightarrow\\
%\PSI{O.\star\,:\, s}Hv
%\end{align*}
%
%}

%\begin{multline}
%%\mc as{\heap a{\OPT t}} \Rightarrow \mc t{\cOPT{a\,}s}{\heap a{\BH}} \\
%\mc x{\cOPT as}{\heapp x{\PAP f{a_{1}\cdots a_{n}}}f{\FUN{x_{1}\cdots x_{m}}e}} \\ \Rightarrow  \OMEGA{\cOFUN{x_{n+1}\cdots x_{m}}as}H{e[a_{1}/x_{1}\cdots a_{n}/x_{n}]}\\
%%\mc v{O.\star\,:\, s}{\nheap v{\THUNK e}} & \Rightarrow & \PSI{O.\star\,:\, s}Hv
%\end{multline}

\subsubsection{Problem med CBV-semantiken}
\label{CBV:Problem}

Ovanstående optimisesemantik bryter mot semantiken för STG. 
Det enda i STG:s semantik som kan framkalla en thunkforcering är om den ligger i en \kw{case}-granskare. 
Det är endast om funktionen som optimeras hade forcerat en thunk under vanlig 
körning som optimise också ska vara tillåten att göra det. Ibland finns det anledning 
att forcera även vid andra tillfällen, men vårt naiva tillvägagångsätt gör det
för mycket.

\begin{codeEx}
take n list = if (n == 0) Nil (head list : take (n-1) (tail list))
\end{codeEx}
Här vill man först evaluera \ic{n == 0} innan något av argumenten till \ic{if}.
\ic{If} är definierad med en \kw{case}-sats på det första argumentet, men även om
\ic{if} infogas så kommer inte \kw{case}-satsen att ligga först i funktionen. För att bättre 
förstå varför kan vi observera hur \ic{take}-koden ser ut osockrad:

\begin{codeEx}
take n list = let 
    { t1 = THUNK (n == 0)
    ; t2 = THUNK (head list)
    ; t3 = THUNK (n - 1)
    ; t4 = THUNK (tail list)
    ; t5 = THUNK (take t3 t4)
    } in  if t1 Nil t5;
\end{codeEx}

Vi evaluerar varje ny thunk efter att vi har passerat den, och när vi kommer till 
\ic{t5} görs ett rekursivt anrop till \ic{take} och processen börjar om.
\ic{if t1 Nil t5} får aldrig en chans att avbryta loopen och optimeringen terminerar aldrig.

Definieras \ic{take} istället på följande sätt terminerar optimise:

\begin{codeEx}
take n list = case n == 0 of
    { True -> Nil
    ; False -> let 
        { t2 = THUNK (head list)
        ; t3 = THUNK (n - 1)
        ; t4 = THUNK (tail list)
        } in  take t3 t4
    };
\end{codeEx}

%\NOTE{oeftersträvansvärt var ordet}

% formellt och bra! /Dan
Det är oeftersträvansvärt att tvinga användarna att skriva alla funktioner
de vill optimera med detta i åtanke. Användaren behöver inte bara hålla reda på 
hur de egna funktionerna är skrivna, men också hur alla funktioner han använder är skrivna. 
Detta arbetar emot abstraktionsprincipen, och skulle vara ett väldigt jobbigt
sätt att skriva kod på. 
% lite informellare igen... :( /Dan
Detta leder oss in på vår strävan efter en lat optimeringssemantik.


\end{document}
