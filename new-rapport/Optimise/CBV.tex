\documentclass[../Optimise]{subfiles}
\begin{document}


\subsection{Call by Value semantik}
Vi har använd ett par olika semantiker för att beskriva optimeringsskeded
i vårt språk, vi ska nu förklara var och ett av dessa i kronologisk
ordning.


Detta optimeringspass arbetar sig igenom träded på ett sätt inte
helt olikt stg-maskinen, dock kan vi bland annat gå in och evaluera
funktion utan att känna till alla argument, s.k. evaluera under lambdat.
För att inte duplicera för mycket av stg funktionallitet så anropas
optimise stg för dvs uppgifter.


\paragraph{Det finns tre delar i optimeringen}


\paragraph{Omega, Ingångspunkten till optimeringsfunktionen, anropas från maskinen
när något har blivit annoterat för optimering. Omega bryter ner träded
och delegerar vidare vem och vad som ska ske, samt lägger ut kontinuations
för att senare bygga upp ett förhoppningsvis ny träd. }

\begin{align*}
\OMEGA sH{\eCase e{brs}} & \Rightarrow & \OMEGA{\oCase{brs}s}He\\
\OMEGA sH{f\,\bar{k}} & \Rightarrow & \mc{f\,\bar{k}}sH\\
\OMEGA sH{f\,\bar{x}\, k\,\bar{y}} & \Rightarrow & \mc{f\,\bar{x}\, k\,\bar{y}}{\oInline s}H\\
\OMEGA sH{\eLet x{\THUNK e}{e'}} & \Rightarrow & \OMEGA{\oLet x{e'}s}He\\
\OMEGA s{\nheap x{\,}}{\bullet} & \Rightarrow & \IRR sH{\bullet}\end{align*}



\paragraph{Irr, kortform för Irreducable. Anropas när Omega eller Psi inte längre
kan optimeringa vidare. Irr kan då utifrån nuvarande continuations
bygga träded eller byta continuation och fortsätta optimera på en
andra delar i uttrycket. Där är här vi kan tillslut fly tillbaka till
stgmaskinen.}

\begin{align*}
\IRR{\oLet xes}H{e'} & \Rightarrow & \OMEGA{\oLetObj x{\THUNK{e'}}s}He\\
\IRR{\oCase{brs}s}He & \Rightarrow & \IRR sH{ECase\, e\, brs}\end{align*}


Istället för att skapa en ECase e brs har vi även testat att gå in
och optimera varje branch, detta brytter dock semantiken, vi kan fastna
i oändliga loopar i brancher vi aldrig hade hamnat i. 

\begin{codeEx}
case x of
    True  -> 5 : Nil
    False -> repeat 1
\end{codeEx}
%\selectlanguage{english}%
Om x är okänd och vi försöker optimera False branchen kommer vi fastna
i en oändlig loop, dock är det möjligt att när programet körs kommer
x bara anta värdet True. 

\begin{align*}
\IRR{\oLetObj x{OBJ}s}He & \Rightarrow & \IRR sH{\eLet x{OBJ}e}\\
\IRR{\cOFUN{\bar{x}}{\alpha}s}He & \Rightarrow & \mc{\alpha}s{\heap{\alpha}{\FUN{\bar{x}}e}}\end{align*}



\paragraph{Psi, anropas från när optimise har lagt ut något åt maskinen och
maskinen inte kan komma längre. Psi kommer använda värdet från maskinen
och sedan delegera vidare optimeringen.}

\begin{align*}
\PSI{\oLet xes}Hv & \Rightarrow & \PSI sH{e[v/x]}\end{align*}


Här byter vi ut alla x mot värdet v som maskinen har arbetat fram.
Här använder vi en substitute funktion som går igenom hela e uttrycksträd
vilket är väldigt kostsamt. Något som vi bytte ut i senare versioner.

\begin{align*}
\PSI{\oLetObj x{OBJ}s}Hv & \Rightarrow & \IRR sH{\eLet x{OBJ}v}\\
\PSI{\oCase{brs}s}Hv & \Rightarrow & \OMEGA sH{\text{instantiate correct brs with v}}\end{align*}


Instantiate correct branch väljer helt enkelt vilken branch som matchar
värdet som maskinen arbetat fram. Detta är troligtvis en av de viktigaste
stegen i vår optimering då kan skala bort alla onödiga brancher, minska
koden och oftast fortsätta optimera en bit in det nya uttrycket.


\paragraph*{Stg, då vi interagerar med stg maskinen måste vi har tydliga regler
för när maskien ska sluta evaluera och börja optimera. Detta sker
antingen då den stöter på en OPT(t) för första gången, eller när den
inte längre kan evaluera ett uttryck och har en Optimise kontinuation
på stacken.}

\begin{align*}
\mc as{\heap a{\OPT t}} & \Rightarrow\\
\mc t{\cOPT{a\,}s}{\heap a{\BH}}\\
\mc x{\cOPT as}{\heapp x{\PAP f{a_{1}\cdots a_{n}}}f{\FUN{x_{1}\cdots x_{m}}e}} & \Rightarrow\\
\OMEGA{\cOFUN{x_{n+1}\cdots x_{m}}as}H{e[a_{1}/x_{1}\cdots a_{n}/x_{n}]}\\
\mc v{O.\star\,:\, s}{\nheap v{\THUNK e}} & \Rightarrow\\
\PSI{O.\star\,:\, s}Hv\end{align*}


Oturligt nog bröt ovanstående optimise semantik mot stgs egna semantik. Som bekant forceras evaluering av thunkar endast i case-granskaren. Om funktionen som optimeras hade forcerat en
thunk under vanlig körning så är opimise också tillåten att göra detta. Det finns ibland anledning att focera även vid andra tillfällen, men vårt naiva tillvägagångsätt höll inte måttet.

\begin{codeEx}
        take n list = if (n == 0) Nil (head list : take (n-1) (tail list))
\end{codeEx}
Här vill man först evaluera n == 0 innan någon av argumenten till if.
If är defienierad med en case sats på det första argumentet. Även om
if inlinas så ligger inte casen-först i funktionen. För att bättre förstå varför kan vi observera hur take koden ser ut osockrad. 

\begin{codeEx}
  take n list = let t1 = THUNK (n == 0)
                    t2 = THUNK (head list)
                    t3 = THUNK (n - 1)
                    t4 = THUNK (tail list)
                    t5 = THUNK (take t3 t4)
                in  if t1 Nil t5
\end{codeEx}

Vi evaluerar varje ny thunk efter vi passerat den, när vi kommer till t5 görs ett rekursivt anrop till take och processen börjar om. `if t1 Nil t5' får aldrig en chans att avbryta loopen och optimeringen terminerar aldrig.

Definierades take istället på följande sättet terminerar optimise:

\begin{codeEx}
  take n list = case n == 0 of
                    True -> Nil
                    False -> let t2 = THUNK (head list)
                                 t3 = THUNK (n - 1)
                                 t4 = THUNK (tail list)
                             in  take t3 t4
\end{codeEx}

Och det är oeftersträvansvärt att tvinga användarna att skriva all funktioner
de vill optimera med detta i åtanke. Användaren behöver inte bara hålla reda på hur sina funktioner är skrivan, men också hur alla funktioner han använder är skrivna. Detta arbetar emot principen om abstraktion vilket är orimligt. Detta leder oss in på vår strävan
efter en lat optimeringssemantik.


\end{document}
