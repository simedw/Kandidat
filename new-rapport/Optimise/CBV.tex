\documentclass[../Optimise]{subfiles}
\begin{document}

\numberwithin{equation}{section}

\section{Call-by-value-semantik}
\label{sec:Optimise:CBV}

Här visas det första försöket till en optimeringssemantik som gjordes i det
här projektet, och hur den optimerar de olika uttrycken som finns. 
För att enkelt visa vilket tillstånd optimeringen befinner sig i skrivs tillståndets symbol
före de par av hakparanteser som omsluter maskinens läge. 
En konfiguration i tillståndet $\Omega$ skrivs alltså:

\[
\OMEGA SHe
\]

% Det första försöket till en optimerings-semantik hade vissa brister: den kunnde komma in i
% oändliga loopar och var för aggresiv i sin optimering. 



\paragraph{Funktionsapplikationer}
Om alla argument till en känd funktion är kända kan vi direkt evaluera detta funktionsanrop,
vilket visas i regel \eqref{CBV:Fun1} som alltså går tillbaka till den vanliga maskinen. 
I regel \eqref{CBV:Fun2} finns ett argument som
är känt och vi kommer att infoga hela funktionen. Den infogning sker via en \cont{OInlining}-continuation
som kommer att substituera in argumenten i funktionskroppen. Om ingen av dessa regler
matchades så kan vi inte optimera mer. Regel \eqref{CBV:FunIrr} visar detta genom
att gå till $\Phi$-tillståndet.

\begin{comment}
\begin{align}
\label{CBV:Fun1} \OMEGA SH{f\,\many{k}}  \rulesep &\, \mc{f\,\many{k}}SH\\
 & \many{k} \text{ alla kända} \nonumber \\
\label{CBV:Fun2} \OMEGA SH{f\,\many{x}\, k\,\many{y}}  \rulesep &\, \mc{f\,\many{x}\, k\,\many{y}}{\oInline S}H\\
 & \many{x},\many{y} \text{ okänd, } k \text{ är känd} \nonumber \\
\label{CBV:FunIrr} \OMEGA SH{f\,\many{x}} \rulesep &\, \IRR SH{f\,\many{x}}
\end{align}
\end{comment}

\begin{align}
\label{CBV:Fun1} \OMEGA SH{f\,\many{k}}  \rulesep &\, \mc{f\,\many{k}}SH\\
 & \many{k} \text{ alla kända} \nonumber \\
\label{CBV:Fun2} \OMEGA SH{f\,\many{x}}  \rulesep &\, \mc{f\,\many{x}}{\oInline S}H\\
 & \text{ någon av } \many{x} \text{ är känd} \nonumber \\
\label{CBV:FunIrr} \OMEGA SH{f\,\many{x}} \rulesep &\, \IRR SH{f\,\many{x}} \\
 & \text{ ingen av } \many{x} \text{ kända} \nonumber
\end{align}

Då det inte läggs ut någon continuation för funktionsapplikation finns det ingen regel
ifrån $\Psi$- eller $\Phi$-tillståndet eftersom de arbetar utifrån vilka continuations
som ligger på stacken.



\paragraph{Let-uttryck}

Om ett \kw{let}-uttryck binder ett thunk-objekt evalueras först thunk-uttrycket. 
Detta görs för att kunna optimera mer av den kod som beror på värdet av thunk-uttrycket. Om
maskinen är i tillståndet $\Psi$ \eqref{CBV:LetTPsi} har den lyckats evaluera thunken till ett värde och kan
substituera in det värdet i kroppen av \kw{let}-uttrycket. Om maskinen däremot är i $\Phi$-tillståndet
\eqref{CBV:LetTIrr} betyder det att den inte kunde optimera fram något värde,
så värdet för thunken stoppas tillbaka och maskinen fortsätter att
optimera kroppen. Notera att positionen för $\bullet$ i continuation:en på stacken
i den regeln ändras för att tala om var optimeringen görs.

\begin{align}
\label{CBV:LetTOmg} \OMEGA SH{\eLet x{\THUNK e}{e'}}  \rulesep &\, \OMEGA{\oLet x{e'}S}He\\
\label{CBV:LetTPsi} \PSI{\oLet xeS}Hv  \rulesep &\, \OMEGA SH{e[v/x]} \\
\label{CBV:LetTIrr} \IRR{\oLet xeS}H{e'}  \rulesep &\, \OMEGA{\oLetObj x{\THUNK{e'}}S}He
\end{align}

Om objektet inte är en thunk kan två olika saker ske. Regeln \eqref{CBV:OLet1} appliceras när det är 
ett känt \obj{CON}-objekt. Då allokeras det på heapen på samma sätt som STG-maskinen gör
och optimeringen fortsätter på det inre uttrycket. I regel \eqref{CBV:OLet2} 
fortsätter optimeringen på inre uttrycket. Här är objekten alltså
inte thunkar.

$\Psi$ och $\Phi$ bygger bara upp \kw{let}-uttrycket igen och går vidare till $\Phi$-tillståndet
eftersom optimeringen inte är färdig ännu (\eqref{CBV:OLet3} och \eqref{CBV:OLet4}). 
Ett problem här är när det finns ett \kw{let}-uttryck
i en \kw{case}-granskare. Då kommer ingen gren att väljas, trots att det finns ett värde. Ett
exempel på detta är följande:

\begin{codeEx}
foo x = case (let y = CON (X 2) in y) of
    { X z -> ..
    };
\end{codeEx} 

I detta fall är granskarens värde konstruktorn \ic{X} och värdet på \ic{z} $2$, men optimeraren
kommer inte att se detta. Det här är en brist som löses senare i detta arbete.

\begin{align}
% FEL!
% Substituera x mot v i e, samt lägg inte ut continuationeen
% [x] <-- fyll i om det är fixat (alt ta bort kommentaren)
\label{CBV:OLet1} \OMEGA SH{\eLet x{\CON{C}{\many{a}}}{e}}  \rulesep &\, \OMEGA S{\heap{v}{\CON{C}{\many{a}}}}{e[v/x]}\\
 & \many{a} \text{ alla kända, } v \text{ ny variabel} \nonumber \\
\label{CBV:OLet2}\OMEGA SH{\eLet x{OBJ}{e}}  \rulesep &\, \OMEGA{\oLetObj x{OBJ}S}He\\
\label{CBV:OLet3}\PSI{\oLetObj x{OBJ}S}Hv  \rulesep &\, \IRR SH{\eLet x{OBJ}v}\\
\label{CBV:OLet4}\IRR{\oLetObj x{OBJ}S}He  \rulesep &\, \IRR SH{\eLet x{OBJ}e}
\end{align}


\paragraph{Case}
\label{cbv:case}
För att kunna optimera ett \kw{case}-uttryck behövs vetskap om vad granskaren är,
så i tillståndet $\Omega$, regel \eqref{CBV:CaseOmg}, börjar granskaren optimeras, och en
\cont{OCase}-continuation läggs ut på stacken för att maskinen ska komma ihåg att den är i en \kw{case}.

I tillståndet $\Psi$ i regel \eqref{CBV:CasePsi} är granskaren ett värde och maskinen väljer helt
enkelt den gren som matchar värdet och instansierar den.
Detta är troligtvis ett av de viktigaste stegen i optimeringen då det skalar bort alla onödiga 
grenar, minskar koden och ofta kan fortsätta optimera en bit in det nya uttrycket.

Istället för att skapa en $\eCase e brs$ i \eqref{CBV:CaseIrr} finns det även
funktionalitet för att
optimera varje gren. Detta gör dock så att optimeringen kan fastna
i en oändlig loopar när den optimerar grenar som programmet aldrig hade exekverat
vid en vanlig körning som i följande exempel: 

\begin{codeEx}
case x of
    { True  -> 5 : Nil
    ; False -> repeat 1
    }
\end{codeEx}

Om \ic{x} är okänt under optimeringen och den optimerar i grenarna kommer 
\ic{repeat 1} att infogas obegränsat antal gånger. Detta är felaktigt då denna loop bara skulle uppstå
om \ic{x} någon gång var \kw{False}.

\begin{align}
\label{CBV:CaseOmg} \OMEGA SH{\eCase e{brs}} \rulesep &\, \OMEGA{\oCase{brs}S}He\\
\label{CBV:CasePsi} \PSI{\oCase{brs}S}Hv \rulesep &\, \OMEGA SH{\text{instansiera korrekt gren av brs med v}} \\
\label{CBV:CaseIrr} \IRR{\oCase{brs}S}He \rulesep &\, \IRR SH{\eCase e brs}
\end{align}


\paragraph{Atomer}
Om det finns en variabel som kod, och den pekar på en thunk i heapen, så optimeras
uttrycket som den pekar på. Alla atomer utom thunkar är värden, och därför går maskinen
då till $\Psi$-tillståndet.
\begin{align}
\OMEGA S{\heap{v}{\THUNK{e}}}v \rulesep &\, \OMEGA SHe \\
\OMEGA SHa \rulesep &\, \PSI SHa
\end{align}


\paragraph{Gränssnitt mot STG}
När optimeringen ska interagera med STG-maskinen måste det finnas tydliga regler
för när maskinen ska sluta evaluera och börja optimera. Detta sker
antingen då den stöter på en $\OPT t$ för första gången, eller när den
inte längre kan evaluera ett uttryck och har en Optimise-continuation
på stacken.

Följande regel sätter upp maskinen i läge för att optimera atomen $a$. Men om $a$
är en thunk behöver den först evalueras till ett värde. Därför läggs
OPT-continuationen ut för att skrida till verket då maskinen har evaluerat
$a$ till ett värde.

\begin{align}
\mc aS{\heap a{\OPT t}} & \rulesep\\
\mc t{\cOPT{a\,}S}{\heap a{\BH}} \nonumber
\end{align}

När ett värde i form av ett \obj{PAP}-objekt nås börjar funktionen optimeras. 
De kända argumenten substitueras in:

\begin{align}
\mc x{\cOPT aS}{\heapp x{\PAP f{a_{1}\ldots a_{n}}}f{\FUN{x_{1}\ldots x_{m}}e}} & \rulesep\\
\OMEGA{\cOFUN{x_{n+1}\ldots x_{m}}aS}H{e[a_{1}/x_{1}\ldots a_{n}/x_{n}]} \nonumber
\end{align}

 I regel \eqref{CBV:Fun3} ska en optimerad funktion byggas upp igen och tillståndet
 går tillbaka till den vanliga maskinen:

\begin{align}
\label{CBV:Fun3} \IRR{\cOFUN{\many{x}}{\alpha}S}He  \rulesep &\, \mc{\alpha}S{\heap{\alpha}{\FUN{\many{x}}e}}
\end{align}

Ibland används STG-maskinen för att evaluera t.ex. konstantuttryck under optimeringen.
Dessa reduceras alltid till värden och därefter anropas $\Psi$ som tar hand 
om detta värde. $O\star$ står här för alla continuations som har med optimering
att göra, som alla börjar på $O$. Detta är alltså hur maskinen kommer 
tillbaka till optimeringstillstånden efter ha evaluerat en funktion med 
kända argument.

\begin{align}
\mc v{O\star\,:\, S}{\nheap v{\THUNK e}} & \rulesep\\
\PSI{O\star\,:\, S}Hv \nonumber
\end{align}

%\NOTE {
%\begin{align*}
%\OMEGA sH{\eCase e{brs}} & \rulesep & \OMEGA{\oCase{brs}s}He\\
%\OMEGA sH{f\,\bar{k}} & \rulesep & \mc{f\,\bar{k}}sH\\
%\OMEGA sH{f\,\bar{x}\, k\,\bar{y}} & \rulesep & \mc{f\,\bar{x}\, k\,\bar{y}}{\oInline s}H\\
%\OMEGA sH{\eLet x{\THUNK e}{e'}} & \rulesep & \OMEGA{\oLet x{e'}s}He\\
%\OMEGA s{\nheap x{\,}}{\bullet} & \rulesep & \IRR sH{\bullet}
%\end{align*}
%
%\begin{align*}
%\PSI{\oLet xes}Hv & \rulesep & \OMEGA sH{e[v/x]}
%\end{align*}
%
%\begin{align*}
%\PSI{\oLetObj x{OBJ}s}Hv & \rulesep & \IRR sH{\eLet x{OBJ}v}\\
%\PSI{\oCase{brs}s}Hv & \rulesep & \OMEGA sH{\text{instantiate correct brs with v}}\end{align*}
%
%\begin{align*}
%\IRR{\oLet xes}H{e'} & \rulesep & \OMEGA{\oLetObj x{\THUNK{e'}}s}He\\
%\IRR{\oCase{brs}s}He & \rulesep & \IRR sH{\eCase e brs}
%\end{align*}
%
%\begin{align*}
%\IRR{\oLetObj x{OBJ}s}He & \rulesep & \IRR sH{\eLet x{OBJ}e}\\
%\IRR{\cOFUN{\bar{x}}{\alpha}s}He & \rulesep & \mc{\alpha}s{\heap{\alpha}{\FUN{\bar{x}}e}}
%\end{align*}
%
%När vi interagerar med STG maskinen måste vi har tydliga regler
%för när maskien ska sluta evaluera och börja optimera. Detta sker
%antingen då den stöter på en $\OPT t$ för första gången, eller när den
%inte längre kan evaluera ett uttryck$ och har en Optimise continuation
%på stacken.

%\begin{align*}
%\mc as{\heap a{\OPT t}} & \rulesep\\
%\mc t{\cOPT{a\,}s}{\heap a{\BH}}\\
%\mc x{\cOPT as}{\heapp x{\PAP f{a_{1}\cdots a_{n}}}f{\FUN{x_{1}\cdots x_{m}}e}} & \rulesep\\
%\OMEGA{\cOFUN{x_{n+1}\cdots x_{m}}as}H{e[a_{1}/x_{1}\cdots a_{n}/x_{n}]}\\
%\mc v{O.\star\,:\, s}{\nheap v{\THUNK e}} & \rulesep\\
%\PSI{O.\star\,:\, s}Hv
%\end{align*}
%
%}

%\begin{multline}
%%\mc as{\heap a{\OPT t}} \rulesep \mc t{\cOPT{a\,}s}{\heap a{\BH}} \\
%\mc x{\cOPT as}{\heapp x{\PAP f{a_{1}\cdots a_{n}}}f{\FUN{x_{1}\cdots x_{m}}e}} \\ \rulesep  \OMEGA{\cOFUN{x_{n+1}\cdots x_{m}}as}H{e[a_{1}/x_{1}\cdots a_{n}/x_{n}]}\\
%%\mc v{O.\star\,:\, s}{\nheap v{\THUNK e}} & \rulesep & \PSI{O.\star\,:\, s}Hv
%\end{multline}

\subsubsection{Problem med CBV-semantiken}
\label{CBV:Problem}

Ovanstående optimeringssemantik bryter mot semantiken för STG. 
Det enda i STG:s semantik som kan framkalla en forcerad evaluering av ett
\obj{THUNK}-objekt är om den ligger i en \kw{case}-granskare. 
Det är endast om funktionen som optimeras hade forcerat en thunk under vanlig 
körning som optimise också borde vara tillåten att göra det. Ibland finns 
det ändå anledning att forcera även vid andra tillfällen, men det tillvägagångssätt,
som presenterats här, visar sig vara för naivt och gör det för mycket. För
att illustrera när detta sker, betrakta följande kodexempel av \ic{take},
som returnerar de första \ic{n} elementen i en lista \ic{list}:

\begin{codeEx}
take n list = if (n == 0) 
                 Nil 
                 (head list : take (n-1) (tail list))
\end{codeEx}

Här skulle det vara bäst att först evaluera \ic{n == 0} innan något av de andra argumenten till \ic{if} 
(som är definierad med en \kw{case}-sats på det första argumentet) evalueras, men även om
\ic{if} infogas så kommer inte \kw{case}-satsen att ligga först i funktionen. 
Så här ser \ic{take}-koden ut osockrad, vilket bättre illustrerar varför:

\begin{codeEx}
take n list = let 
    { t1 = THUNK (n == 0)
    ; t2 = THUNK (head list)
    ; t3 = THUNK (n - 1)
    ; t4 = THUNK (tail list)
    ; t5 = THUNK (take t3 t4)
    } in  if t1 Nil t5;
\end{codeEx}

Varje ny thunk evalueras efter att den har passerats, och när optimeraren når 
\ic{t5} görs ett rekursivt anrop till \ic{take} och processen börjar om.
\ic{if t1 Nil t5} får aldrig en chans att avbryta loopen och optimeringen terminerar aldrig.

Definieras \ic{take} istället på följande sätt terminerar optimise:

\begin{codeEx}
take n list = case n == 0 of
    { True -> Nil
    ; False -> let 
        { t2 = THUNK (head list)
        ; t3 = THUNK (n - 1)
        ; t4 = THUNK (tail list)
        } in  take t3 t4
    };
\end{codeEx}

%\NOTE{oeftersträvansvärt var ordet}

% formellt och bra! /Dan
Att tvinga användarna att skriva alla funktioner
de vill optimera med detta i åtanke är något som ska undvikas.
 Användaren behöver inte bara hålla reda på 
hur de egna funktionerna är skrivna, men också hur alla funktioner som används är skrivna. 
Detta strider mot abstraktionsprincipen, och skulle vara ett omständigt sätt
 att skriva kod på. 
% lite informellare igen... :( /Dan
En lat optimering skulle vara bättre, vilket leder in kommande avsnitt om
call-by-name-semantik, \ref{sec:Optimise:CBN}.


\end{document}
