\documentclass[Rapport]{subfiles}
\begin{document}


\section{Diskussion}
    
Vi har gjort en tolk för ett funktionellt programmeringsspråk
med en semantik som följer STG-maskinen som används i Haskellkompilatorn GHC.
Till denna har vi lagt till möjligheten att optimera partiellt applicerade funktioner under körningstid
då vi känner till värdena som applicerades och kan utnyttja dessa till optimering.

\subsection{Varför optimering under körningstid?}

En relevant fråga att ställa sig är varför man i huvudtaget vill göra optimeringar under körningstid. Faktum är att många av de optimeringar vi gör kan köras statiskt, som här:

\begin{codeEx}

foo x = case x of
        { A y  -> e1
        ; B z  -> e2
        };

\end{codeEx}

Vid statiskt optimering vet vi inte vilken av grenarna som kommer att väljas. Dock skulle en kompilator kunna skapa två olika versioner, en för \ic{A}-grenen och en för 
\ic{B}-grenen. Sedan under körningstid behöver man kolla på \ic{x} en gång för att sedan avgöra vilken av de optimerade grenarna man ska använda.
Som vi nämnt tidigare har inte kompilatorer samma tidsrestriktion vid optimeringar som vi har under körningstid, vilket kan göra detta till en rimlig lösning. Det finns ändå ett par nackdelar:
\begin{itemize}
    \item Det kan ta väldigt långt tid. Tänk dig \ic{power} funktionen men en specialversion för varje heltal som finns. (Naturligtvis hade man använt någon mekanism för att annotera vad som ska specialiseras och inte)
    \item Det kan vara svårt att förutspå vad som kommer att används ofta och därför är värt att specialisera. Vår optimise körs bara om den någon gång anropas.
    \item Små program kan blir mycket stora när en version av varje input måste lagras.
\end{itemize}


Det finns också kritik mot att partiell evaluering som optimering endast är användbart för konstruerade problem, till exempel uträkning av fakultet eller skalärprodukt. Vi har försökt visa på mer verkliga fall där det kan vara mycket användbart genom att optimera en raytracer och fått goda resultat. 


\subsection{Placering av optimise}

Vi valde att programmeraren själv skulle  specificera var i koden vi skulle optimera. Det har har visat sig att detta inte alltid är trivialt och som programmerare måste man ta hänsyn till flera olika saker för att få bra prestanda. Att sätta optimise på helt fel ställe kan till och med göra programmet flera gånger långsammare.

Vi kunde istället ha gjort som man gör i de flesta just in time-kompilatorer. De noterar så kallade hotspots i koden, delar av koden som körs många gånger, och börjar sedan antingen optimera eller kompilera de delarna. Då kan vi inte längre använda våra semantikförstörande utökningar (se \ref{sec:Optimise:With}) vilket ofta krävs för att få någon verklig prestandavinst. 






\subsection{Implementerbarhet i kompilator}
Vi valde att göra en tolk eftersom det ofta är enklare än att implementera en kompilator.
En tolk innebär att man känner till syntaxträdet hos koden, vilket vanligtvis kompilerad
kod inte gör, vilket gör att om det skulle implementeras i en kompilator skulle
denna information behöva kompileras ner för att finnas tillgänglig när programmet körs.


\subsection{Lathet}
Vid optimeringen vill man att koden ska bli så optimerad som möjligt, men man får
vara försiktig så att man inte är för aggressiv, 
eftersom det kan leda till icke-terminering. Det sker exempelvis i det här fallet:

\begin{codeEx}
take n xs = let
    { a1 = THUNK (n == 0)
    ; a2 = THUNK (case xs of
        { Nil -> Nil
        ; Cons x ys -> let
            { b1 = THUNK (n - 1)
            } in take b1 ys
        }
    } in if a1 Nil a2;

main = (optimise (take 5)) [1,2,3,4,5,6,7];
\end{codeEx}

I exemplet ovan skulle en sämre designad optimise-funktion gå in och optimera \ic{a2} oberoende av värdet på
\ic{a1}, och eftersom värdet på \ic{xs} inte är känt när funktionen optimeras leder det till
icke-terminering om man infogar det rekursiva anropet till \ic{take}.
    Den första semantiken som presenterades led av detta problem, men löstes i den senare med hjälp av
en semantik som var latare, inte forcerade evaluering av alla thunkar och närmare semantiken från STG.

%%% Flytta till relaterade arbeten?
Det finns andra sätt förhindra icke-terminering, i \cite{mitchell2007supercompiler} 
används en vidareutveckling av \cite{home-emb}. Där används ett kriterium för att se om infogad kod kommer att anropa på sig själv utan att minska på sina argument. Uppfylls detta avbryts infogningen. Detta ämnar sig något bättre för optimeringar som arbetar med omskrivningsregler och troligtvis inte lika bra för vår mer evalueringsinriktade metod.



\subsection{Optimise-with}
En annan möjlig lösning på problemet ovan är att låta programmeraren själv avgöra hur
många gånger en funktion får infogas, som här:

\begin{codeEx}
main = optimise (take 5) with { inline take 5 } [1,2,3,4,5,6,7];
\end{codeEx}

I exemplet ovan betyder \ic{inline take 5} att \ic{take} bara får infogas $5$ gånger.
En funktionalitet som skulle kunna gynna optimise, eller användandet av den,
är att den skulle kunna detektera när den potentiellt skulle falla in i en
oändlig infogningsloop. Det har inte gjorts till det här arbetet.

\subsection{Delning}
Ett annat problem förknippat med lathet är att optimise måste se till att variabler bara 
evalueras en gång. Detta ställer till besvär hur man skall optimera \kw{let}-satser.
Ett exempel på delning är detta:

\begin{codeEx}
test x y = let
    { a = THUNK (fib x + y)
    } in a + a;

main = optimise (test 10) 5;
\end{codeEx}

Med vår senare semantik infogas först additionen, och sedan infogas thunkens innehåll
som motsvarar \ic{a}. Det gör att optimise sedan kommer att
köras två gånger på samma kod. Med en optimering som tog delning i åtanke 
skulle dela resultatet av att optimera a och använda det på båda ställen där det används.

En optimerad version är denna, eller en med additionen infogad
\footnote{Notera att \ic{fib 10 = 55}}:

\begin{codeEx}
test_x y = let
    { a = THUNK (55 + y)
    } in a + a;
\end{codeEx}

\subsection{Anropsstack}

I projektets tidigare fas användes substituering för att göra exempelvis funktionsapplikation.
Det betyder att syntaxträdet traverseras och argumentvariablerna byts i funktionen
mot vad argumenten faktiskt är. Detta är långsamt och inte särskilt realistiskt - 
speciellt inte om man talar om en kompilator. Kompilatorer kan istället använda anropsstackar
där man låter funktionsargumenten indexeras in på en stack, så att man slipper
gå ner i hela syntaxträdet. Det är vanligtvis inte omöjligt i kompilerad kod eftersom
det inte finns någon tillgång till syntaxträdet.

För att göra vår tolk mer realistisk byttes substitueringen till en anropsstack 
Det gav också en hastighetsökning av tolken med ungefär 2500\%.

%\subsection{Optimise med anropsstack}

Att översätt optimise till att arbete med en anropsstack var relativt svårt. Varje gång en funktion infogades, eller någon \kw{let} kunde tas bort behövde alla efterkommande index räknas om. 


\end{document}
