\documentclass[Rapport]{subfiles}
\begin{document}


\chapter{Diskussion}
    
Vi har gjort en tolk för ett funktionellt programmeringsspråk
med en semantik som följer STG-maskinen som används i Haskellkompilatorn GHC.
Till denna har vi lagt till möjligheten att optimera partiellt applicerade funktioner under körningstid
då vi känner till några av argumenten till funktionen och kan utnyttja dessa till optimering.

\paragraph{Varför optimering under körningstid?}

En relevant fråga att ställa sig är varför man i huvudtaget vill göra optimeringar under körningstid. Faktum är att många av de optimeringar vi gör kan köras statiskt, som här:

\begin{codeEx}

foo x = case x of
        { A y  -> e1
        ; B z  -> e2
        };

\end{codeEx}

Vid statisk optimering vet vi inte vilken av grenarna som kommer att väljas. Dock skulle en kompilator kunna skapa två olika versioner, en för \ic{A}-grenen och en för 
\ic{B}-grenen. Sedan, under körningstid, behöver man bara titta på \ic{x} en gång för att sedan avgöra vilken av de optimerade grenarna man ska använda.
Som vi nämnt tidigare har inte kompilatorer samma tidsrestriktion vid optimeringar som vi har under körningstid, vilket kan göra detta till en rimlig lösning. Det finns ändå ett par nackdelar:
\begin{itemize}
    \item Det kan ta väldigt långt tid. Tänk dig \ic{power}-funktionen men en specialversion för varje heltal som finns. Det skulle kunna begränsas med någon mekanism för att annotera vad som ska specialiseras och inte.
    \item Det kan vara svårt att förutse vad som kommer att användas ofta och därför är värt att specialisera. Vår \ic{optimise}-funktion körs bara om den någon gång anropas.
    \item Små program kan blir mycket stora när en version av varje indata måste lagras.
\end{itemize}


Det finns också kritik mot att partiell evaluering som optimering endast är användbart för konstruerade problem, till exempel uträkning av fakultet eller skalärprodukt. Vi har försökt visa på mer verkliga fall där det kan vara mycket användbart genom att optimera en raytracer och fått goda resultat. 


\paragraph{Placering av optimise}

Vi valde att programmeraren själv skulle  specificera var i koden vi skulle optimera. Det har visat sig att detta inte alltid är trivialt och som programmerare måste man ta hänsyn till flera olika saker för att få bra prestanda. Att sätta \ic {optimise} på helt fel ställe kan till och med göra programmet långsammare.

Vi kunde istället ha gjort som man gör i de flesta just in time-kompilatorer. Då markeras så kallade hotspots i koden, delar av koden som körs många gånger, och börjar sedan antingen optimera eller kompilera de delarna. Men då skulle vi inte längre kunna använda våra semantiköverskridande utökningar (se \ref{sec:Optimise:With}) vilket ofta krävs för att få någon verklig prestandavinst. 


\paragraph{Implementerbarhet i kompilator}
Vi valde att göra en tolk eftersom det ofta är enklare än att implementera en kompilator.
En tolk innebär att man känner till syntaxträdet hos koden, vilket vanligtvis kompilerad
kod inte gör. Om det skulle implementeras i en kompilator skulle
denna information behöva kompileras ner för att finnas tillgänglig när programmet körs.


\paragraph{Lathet}
Vid optimeringen vill man att koden ska bli så optimerad som möjligt, men man får
vara försiktig så att man inte är för aggressiv, 
eftersom det kan leda till icke-terminering. Det sker exempelvis i det här fallet:

\begin{codeEx}
take n xs = let
    { a1 = THUNK (n == 0)
    ; a2 = THUNK (case xs of
        { Nil -> Nil
        ; Cons x ys -> let
            { b1 = THUNK (n - 1)
            } in take b1 ys
        }
    } in if a1 Nil a2;

main = (optimise (take 5)) [1,2,3,4,5,6,7];
\end{codeEx}

I exemplet ovan skulle en sämre designad optimise-funktion gå in och optimera \ic{a2} oberoende av värdet på
\ic{a1}, och eftersom värdet på \ic{xs} inte är känt när funktionen optimeras leder det till
icke-terminering om man infogar det rekursiva anropet till \ic{take}.
    Den första semantiken som presenterades led av detta problem, men det löstes i den senare med hjälp av
en semantik som var latare, inte forcerade evaluering av alla thunkar och låg närmare semantiken för STG.

%%% Flytta till relaterade arbeten?
Det finns andra sätt förhindra icke-terminering.
Det finns ett kriterium för att se om infogad kod kommer att anropa sig själv 
utan att minska på sina argument. Om kriteriet uppfylls avbryts infogningen 
\cite{mitchell2007supercompiler}. Detta lämpar sig bra för optimeringar som 
arbetar med omskrivningsregler och troligtvis inte lika bra för vår mer 
evalueringsinriktade metod som arbetar mer på mikronivå.

\begin{comment}
% jag håller med / dan
\subsection{Optimise-with}
En annan möjlig lösning på problemet ovan är att låta programmeraren själv avgöra hur
många gånger en funktion får infogas, som här:

\begin{codeEx}
main = optimise (take 5) with { inline take 5 } [1,2,3,4,5,6,7];
\end{codeEx}

I exemplet ovan betyder \ic{inline take 5} att \ic{take} bara får infogas $5$ gånger.
En funktionalitet som skulle kunna gynna optimise, eller användandet av den,
är att den skulle kunna detektera när den potentiellt skulle falla in i en
oändlig infogningsloop. Det har inte gjorts till det här arbetet.
\end{comment}

\paragraph{Delning}
Ett annat problem förknippat med lathet är att \ic{optimise} måste se till att variabler bara 
evalueras en gång. Detta ställer till besvär med hur man skall optimera \kw{let}-satser.
Ett exempel på delning är detta:

\begin{codeEx}
test x y = let
    { a = THUNK (fib x + y)
    } in a + a;

main = optimise (test 10) 5;
\end{codeEx}

Med vår senare semantik infogas först additionen, och sedan infogas thunkens innehåll
som motsvarar \ic{a}. Det gör att \ic{optimise} sedan kommer att
köras två gånger på samma kod. En optimering som hade delning i åtanke 
skulle dela resultatet av att optimera \ic{a} och använda det på båda ställen där det används.

En optimerad version är denna, eller en med additionen infogad:
\footnote{Notera att \ic{fib 10 = 55}}:

\begin{codeEx}
test_x y = let
    { a = THUNK (55 + y)
    } in a + a;
\end{codeEx}

\paragraph{Anropsstack}

I en tidig fas i projektet användes substituering för att göra exempelvis funktionsapplikation.
Det betyder att syntaxträdet traverseras och argumentvariablerna byts i funktionen
mot vad argumenten faktiskt är. Detta är långsamt och inte särskilt realistiskt - 
speciellt inte om man talar om en kompilator. Kompilatorer kan istället använda anropsstackar
där man låter funktionsargumenten indexeras in på en stack, så att man slipper
gå ner i hela syntaxträdet. Traversering är vanligtvis inte möjligt i kompilerad kod eftersom
det inte finns tillgång till syntaxträdet vid körning.

För att göra vår tolk mer realistisk byttes substitueringen mot en anropsstack. 
Det gav också en hastighetsökning för tolken med ungefär 2500\%.

%\subsection{Optimise med anropsstack}

Att översätta optimise till att arbeta med en anropsstack var relativt svårt. 
Varje gång en funktion infogas, eller ett \kw{let}-uttryck tas bort behöver alla efterkommande index räknas om. 

\paragraph{Olinjär optimeringsstid}
\label{sec:diskussion_om_exponentialitet} %diskussion_om_exponentialitet
Både i raytracern och i powerexemplet ser man att optimeringen kan ta lång tid.
Boven i dramat är det som refererats till \kw{casebranch}-optimeringen. I
\ic{powers}-exemplet är den implicit då denna optimering sker automatiskt
om det bara finns en gren i \kw{case}-satsen. Detta är exakt det som sker 
vid primitiva aritmetiska operationer, när talet boxas och avboxas.

Anledningen till detta är hur välkänd caselag, avsnitt \ref{sec:CaseLaw}, är 
implementerad. Eftersom $\Phi$-tillståndet återigen försöker optimera \kw{case}-uttrycken
när den har skyfflat runt dem kommer optimeringen att gå igenom hela uttrycket igen.
Detta leder till att samma uttryck kommer att försöksoptimeras lika många gånger
som det finns \kw{case}-uttryck.  

Detta leder till att optimeringen i powerexemplet tar lång tid eftersom den har lika
många \kw{case}-uttryck i varandra som talet man skall höja upp med.
Detta förklarar också varför det tar så lång tid att genomföra optimeringen
i raytracerexemplet med \ic{casebranches}. Vissa av funktionerna blir mycket stora med alla infogningar
av transformationer, och de kommer alla ge upphov till onödiga omskyfflingar.
Det testexempel som finns på raytracern har konstant bild som ska målas, och
testar alltså inte att från indata måla upp en bild. Den enda parametern som
justeras är storleken på bilden som genereras.

% Olle: "jag har en ko, en höna och en mus"

\NOTE{
Ett buggigt försök att beskriva varför vi har utformat reglerna.

kan tas bort om det tex är uselt

baserat på den här diskussionen mellan Daniel och Simon:

        i evalueringsform. vi optimerar inte saker ännu inte används
        tracing jit säger Daniel
        hur gör man det jit säger Simon
        Daniel pratar om execution-paths

        det finns troligtvis bättre modeller men vi har inte gjort dem

        vi har inte heller kollat så djupt i litteraturen
            och det var kul att komma på själva
            och det var inte så bra gjort av oss
            men vi får göra så för det är ett kandiatarbete
}

\paragraph{Optimeringsreglernas utformning}
Vi ville undersöka och lösa problemet med att partialevaluera funktioner
under körningstid. Reglerna, som beskrevs i kapitel \ref{sec:Optimise}, 
utformades för detta ändamål. För att få ett abstraktionslager annoterades
maskinens tillstånd med tre mer eller mindre väl valda grekiska bokstäver.
$\Omega$ som representerar att det nuvarande uttrycket ska optimeras.
$\Psi$ att det nuvarande uttrycket är ett värde och att det är intressant
i exempelvis fallet av optimering av \kw{case}-granskare.
När inga fler optimeringar kan genomföras går maskinen in i tillståndet $\Phi$ 
för att åter bygga upp uttrycket.

Dessa tillstånd valdes för att vi tyckte att det underlättade att resonera
om vad optimise tidigare hade gjort och vad den kunde göra härnäst. 
Continuationstacken används också flitigt för att på
ett linjärt vis beskriva vad som har passerats tidigare.
Det var svårt att isolera olika delar av optimeringsmöjligheterna vi gjorde.
Det var en svår balansgång. Vi ville också 
att optimeringen skulle traversera trädet en enda gång och göra flera
saker samtidigt. Vi har delvis lyckats uppnå detta, med två undantag: den nuvarande problematiken med välkänd caselag, i 
föregående paragraf \ref{sec:diskussion_om_exponentialitet} samt 
\emph{Afterburner}, avsnitt \ref{sec:Afterburner}, 
som tar bort överflödiga \kw{case}-granskningar.

\end{document}
