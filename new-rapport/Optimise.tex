
\documentclass[Rapport]{subfiles}
\begin{document}

\section{Optimise}
\label{sec:Optimise}
% svårt att låta bli att alla dessa avsnitt börjar med 
% 'i det här avsnittet [ ska vi undersöka / beskrivs / förklaras ... ]'
% plepp, pleat

\overviewOptimise

Nu när sockerspråket (sektion 2) och STG (sektion 3) är förklarade
kan undersökningen av optimeringen, som är själva kärnan i arbetet, påbörjas.
I introduktionen i detta avsnitt kan du läsa om vad optimering och 
optimering under körningstid innebär. 

För att optimera under körningstid har olika semantiker tagits fram och undersökts.   
Den första av dem, som kommer att refereras till som CBV- eller call-by-value-semantiken, 
beskrivs i avsnitt 4.2. Den hade vissa nackdelar, så i 
efterföljande avsnitt presenteras en bättre lösning som kallas för CBN- eller call-by-name-semantiken.

Denna kunde också tjäna på andra optimeringar, som t.ex.
dödkodseliminering (sektion 4.5), 
välkänd caselag (sektion 4.6) och 
afterburner (sektion 4.7).

Hur optimeringen fungerar tillsammans med anropsstacken visas i det sista avsnittet 4.8.

\subfile{Optimise/Intro}

%\subsection{Optimeringsmaskiner}
\begin{comment}
Statiska optimeringar är ofta uppdelade i olika pass, specialiserade på en viss
typ av optimering\footnote{Vi kan se varje pass som transformen $\llbracket \_ \rrbracket :: syntaxtree \rightarrow syntaxtree$}. Det kan ibland finnas anledning att köra ett pass flera gånger. Till exempel 
kan ett tidigare pass ha skapat nya optimeringsmöjligheter för ett annat, redan kört, pass. 
Att köra dessa pass under kompileringstid är inget större problem, 
men under körningstid finns det större krav på tidseffektivitet, vilket denna iterativa 
metod har svårt att leverera.

Vi valde istället att skriva en ny del av evalueringsmaskinen som tar över när något skall optimeras.
Denna har precis som STG ett antal regler som den följer beroende på vilket
tillstånd den har. Till skillnad från STG tillåts variabler att vara okända när optimeringen
körs, eftersom den är tänkt att köras på partiellt applicerade funktioner eller 
evaluera under lambdat som det också kan kallas.
Precis som STG använder den sig av continuations, vilka används för att bygga upp 
syntaxträdet när optimeringen är klar. Med det här tillvägagångsättet behöver vi 
bara gå igenom syntaxträdet en gång. Vi har delat upp optimeringen i tre tillstånd
som har olika ansvarsområden. Optimeringen kan också gå tillbaka till STG-maskinen
och använda den för att evaluera uttryck, vilket gör att vi slipper duplicera
den funktionaliteten.

%\stgOptimise


\textbf{Omega} $\Omega$, är ingångspunkten till optimeringsfunktionen, och anropas från maskinen
när något har blivit annoterat för optimering. Omega bryter ner trädet
och delegerar vidare vem och vad som ska ske, samt lägger ut continuations
för att senare bygga upp ett (förhoppningsvis) nytt träd.

\textbf{Psi} $\Psi$, anropas när optimise har lagt ut något åt STG-maskinen och
den inte kan komma längre. Psi kommer att använda värdet från maskinen
och sedan delegera vidare optimeringen beroende på det.

\textbf{Irr} $\Phi$, kortform för Irreducible. Anropas när Omega eller Psi inte
kan optimera vidare. Irr kan då utifrån vilka continuations som ligger på stacken
bygga upp trädet eller byta continuation och fortsätta optimera på en
annan del i uttrycket. Det är också här vi till slut går tillbaka till
STG-maskinen.

Vi har använt ett par olika semantiker för att beskriva optimeringen
i vårt språk, och vi ska nu förklara dessa i kronologisk ordning.

\end{comment}

\subsection{Optimeringtillstånd}

% exotiskt att skriva dessa i optimisefilen
% och inte i en ny fil i optimisekatalogen
%  mvh Dan

Vi kommer uttrycka vår optimering på ett liknande sätt som övriga STG. Vi optimerar
koden genom att evaluera den på ett speciellt sätt. En skillnad mellan optimering och
evaluering är att optimeringen sker med okända uttryck (t.ex. fria variabler). 
Det gör att vi inte alltid kan få ett värde\footnote{ Det vill säga en primitiv eller en variabel som inte
är en thunk.}  av en optmering av uttryck, i dessa
fall måste vi bygga upp ett uttryck som kommer räkna ut det okända värdet. Förhopningsvis
är det nya uttrycket för att räkna ut värdet bättre än det gamla.

Vi kommer att se optimeringen som ett specialtillstånd för STG, som används
för att visa att vi evaluerar inuti en funktion (under lambda), vilket alltså medför
att det finns fria variabler. Målet  är att i slutet av optimeringen
ha skapat en ny funktion som är snabbare än orginalfunktionen.

Det som vår optimering kan göra faller under dessa kategorier:

\paragraph{ Beräkna kända uttryck. }
Dessa fall är ganska enkla att optimera här går det att använda den vanliga
maskinen för STG. Om det t.ex står \ic{7 * 191} i koden så kan vi evaluera
det som vanligt och sedan använda resultatet \ic{1337} i koden.

\paragraph{ Infoga funktionsdefinitioner. }

Att infoga funktioner kan se som något enkelt, men det finns vissa fällor att se upp
för. Det gäller att se till att man inte infogar funktioner som i sin tur infogar funktioner etc.
Man får vara försiktig så optimeringen terminerar, detta blir ett problem om man
optimerar inuti alla grenar till ett \kw{case}-uttryck. Detta kan exemplifieras
med funktionen \ic{sum}, som summerar en heltalslista:

\begin{codeEx}
sum xs = case xs of
    { Nil -> 0
    ; Cons y ys -> let
        { a = THUNK (sum ys)
        } in y + a
    };
\end{codeEx}

Om man optimerar \ic{sum} inuti grenarna så finns det risk att man infogar \ic{sum}
igen i \ic{Cons}-fallet.

\paragraph{ Välja rätt gren i \kw{case}-uttryck. }

I \kw{case}-uttryck kan man veta vilket värde en granskare har, detta kan man använda
för att välja rätt gren. När vi hittar en \kw{case} börjar vi optimera granskaren,
men eftersom det inte är avgörbart på förhand om en optimering lyckas eller inte
behöver vi något sätt att visa det. 

I vår implementation har vi valt att visa detta genom att ha tre olika tillstånd
för vår optimering, vilka dessa är och vad de betyder kommer beskrivs senare.

\paragraph{ Byta ut uttryck mot semantiskt ekvialenta uttryck.}

STG-språket följer vissa lagar, dessa kan man använda för att skria om uttryck
till ekvialenta uttryck. Vi har i vissa fall använt dessa lagar för att skriva om
uttrycken till andra uttryck som är enklare att optimera.

\paragraph{}

Då optimeringen kan misslyckas med att ge ett värde behöver vi kunna bygga upp uttryck
igen. För att veta vad som skall byggas upp används stacken för att lägga ut continuations
om vilket uttryck man tidigare har optimerat och som man behöver bygga upp igen ifall det
inte blev ett värde. Så många uttryck får en egen continuation för detta syfte.



Som lösning har vi valt att ha tre olika tillstånd, dessa har vi valt att kalla
$\Omega, \Psi$ samt $\Phi$. Dessa används för att optimeringen skall veta var den
är. 

\paragraph{Omega $\Omega$} Är att maskinen vill optimera till ett värde. I detta tillstånd
inspekterar vi uttrycket och försöker evaluera det till ett värde om det går.

\paragraph{Psi $\Psi$} Är att maskinen har optimerat till ett värde. I detta tillstånd
har vi ett värde och försöker bygga upp uttrycket igen från stacken, med kunskapen att vi vet
att det är ett värde.

\paragraph{Irr $\Phi$} Är att maskinen misslyckats att optimera till ett värde, kortform för Irreducible.
I detta tillstånd har vi att vi inte hade tillräckligt med information att få ett
värde. Så vi bygger upp ett uttryck igen med information från stacken.

\paragraph{}
I figur \ref{fig:Optimise:states} ses att evaluering alltid börjar i den vanliga maskinen
 (visas som STG) och går till $\Omega$. Detta sker när vid optimering av en funktion
och slutar med att $\Phi$ bygger upp funktionen och går tillbaka till den vanliga maskinen.

%\begin{figure}[H]
\stgOptimise
%\caption{Hur tillstånden kan gå mellan varandra}
%\label{fig:Optimise:states}
%\end{figure}







\subfile{Optimise/CBV}

\subfile{Optimise/With}

\subfile{Optimise/CBN}
\subfile{Optimise/DeadCode}
\subfile{Optimise/ValkandCaseLag}
\subfile{Optimise/AfterBurner}

\end{document}
